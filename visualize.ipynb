{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd4c35e-8394-4b48-9222-a45203a45261",
   "metadata": {},
   "source": [
    "## Reading generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f8b14e-6558-4516-8f7d-ef2f0e6d4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv \n",
    "from dotenv import dotenv_values\n",
    "import urllib.request as request\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from IPython.display import clear_output\n",
    "\n",
    "DALLEE_IMAGE_URL = (\n",
    "    \"https://dgmd-s17-assets.s3.amazonaws.com/train/generated-text-images/\"\n",
    ")\n",
    "USE_AWS_AI = False\n",
    "LOCAL_AI_PORT = \"80\"\n",
    "AWS_AI_URL=\"http://34.192.30.136/\"\n",
    "\n",
    "OPENAI_KEY = \"\"\n",
    "load_dotenv()\n",
    "ENV_CONFIG = dict(dotenv_values(\".env\"))\n",
    "try:\n",
    "    OPENAI_KEY = ENV_CONFIG.get(\"OPENAI_KEY\")\n",
    "except KeyError:\n",
    "    raise(Exception(\"Please write OPENAPI_KEY to .env\"))\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,16)\n",
    "plt.rcParams[\"figure.dpi\"] = 40\n",
    "\n",
    "def setup_plt(keep_ticks=False):\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    ax = plt.gca()\n",
    "    if keep_ticks == False:\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "        ax.yaxis.set_tick_params(labelleft=False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "with open('merged.json', 'r') as rf:\n",
    "    data = json.load(rf)\n",
    "\n",
    "prompts = data[\"prompts\"]\n",
    "sources = data[\"images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ebc63a-72dc-45f5-8857-a560ff45250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED 15 IMAGES!\n"
     ]
    }
   ],
   "source": [
    "try: sources\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run prior cell\"))\n",
    "\n",
    "DELAY_READ = 0.001\n",
    "NUM_READ = len(sources)\n",
    "NUM_READ = 15 # TODO\n",
    "\n",
    "images = []\n",
    "print('LOADING IMAGES...')\n",
    "src_subset = sources[:NUM_READ]\n",
    "for src in src_subset:\n",
    "    image_url = DALLEE_IMAGE_URL + src[\"file_name\"]\n",
    "    resp = requests.get(image_url, stream=True).raw\n",
    "    arr = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    decoded = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "    if decoded is None:\n",
    "        print('Unable to load', image_url)\n",
    "        continue\n",
    "    img = decoded[:,:,::-1]\n",
    "    images.append((src,img))\n",
    "    time.sleep(DELAY_READ)\n",
    "    if len(images) % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(round(100*len(images)/len(src_subset)),'%')\n",
    "clear_output(wait=True)\n",
    "print('LOADED', len(images), 'IMAGES!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb15f82-480f-496b-95b5-97cd8e4b4cdd",
   "metadata": {},
   "source": [
    "## Custom OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf352b80-d88d-42bb-b008-67427992ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Custom AI: http://localhost:80/\n",
      "http://localhost:80/predict <Response [500]>\n",
      "http://localhost:80/predict <Response [500]>\n",
      "http://localhost:80/predict <Response [500]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try: images\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run prior cell\"))\n",
    "try: USE_AWS_AI\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run first cell\"))\n",
    "try: AWS_AI_URL\n",
    "except NameError:\n",
    "    if (USE_AWS_AI == False): pass\n",
    "    raise(Exception(\"Please run first cell\"))\n",
    "try: LOCAL_AI_PORT\n",
    "except NameError:\n",
    "    if (USE_AWS_AI == True): pass\n",
    "    raise(Exception(\"Please run first cell\"))\n",
    "\n",
    "AI_SERVER_URL = (\n",
    "    AWS_AI_URL if USE_AWS_AI else f'http://localhost:{LOCAL_AI_PORT}/'\n",
    ")\n",
    "print(f'Using Custom AI: {AI_SERVER_URL}')\n",
    "for (i, (src,img)) in enumerate(images):\n",
    "   bytes = bytearray(cv2.imencode('.png', img)[1])\n",
    "   files = {'file': ('image.png', bytes, 'image/png', {'Expires': '0'})}\n",
    "   endpoint = f'{AI_SERVER_URL}predict'\n",
    "   response = requests.post(endpoint, files=files)\n",
    "   print(endpoint, response) #response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a2c56-716c-4091-85bd-3ea23241978c",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccce0ae-aa4d-496f-b51f-b89fcc30235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "try: images\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run prior cell\"))\n",
    "\n",
    "N_VIZ = len(images)\n",
    "DELAY_VIZ = 0.0\n",
    "print('LOADING MODEL...')\n",
    "reader = easyocr.Reader(['en'])\n",
    "def result_to_box(result):\n",
    "    for r in result:\n",
    "        yield np.round(r[0]).astype(int).tolist()\n",
    "def result_to_words(result):\n",
    "    # TODO -- fix source dataset\n",
    "    ok_err = {\n",
    "        'llspice': 'allspice'\n",
    "    }\n",
    "    for r in result:\n",
    "        yield ok_err.get(r[1],r[1])\n",
    "def src_to_words(src):\n",
    "    meta_words = src[\"words\"]\n",
    "    for lines in meta_words:\n",
    "        for word in lines[\"word\"].split('\\n'):\n",
    "            yield word\n",
    "def src_to_box(src):\n",
    "    meta_words = src[\"words\"]\n",
    "    for box in meta_words:\n",
    "        vecs = []\n",
    "        for point in box[\"points\"]:\n",
    "            vecs.append([point[\"x\"], point[\"y\"]])\n",
    "        yield vecs\n",
    "\n",
    "real_values = []\n",
    "result_values = []\n",
    "for (i, (src,img)) in enumerate(images):\n",
    "    real_box = list(src_to_box(src))\n",
    "    real_words = list(src_to_words(src))\n",
    "    real_text = ' '.join(real_words)\n",
    "    real_values.append({\n",
    "        \"text\": real_text,\n",
    "        \"bounds\": real_box,\n",
    "        \"image\": img\n",
    "    })\n",
    "    result = reader.readtext(img)\n",
    "    result_box = list(result_to_box(result))\n",
    "    result_words = list(result_to_words(result))\n",
    "    result_text = ' '.join(result_words)\n",
    "    result_values.append({\n",
    "        \"text\": result_text,\n",
    "        \"bounds\": result_box,\n",
    "    })\n",
    "    if len(real_values) % 10 == 0:\n",
    "        print(round(100*len(real_values)/len(images)),'%')\n",
    "    if (i >= N_VIZ):\n",
    "        continue\n",
    "    time.sleep(DELAY_VIZ)\n",
    "    setup_plt()\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # Calculate title\n",
    "    correct = result_text == real_text\n",
    "    sep = \"==\" if correct else \"â‰ \"\n",
    "    plt.title(f'{result_text} {sep} {real_text}', fontsize = 30)\n",
    "\n",
    "    # Draw predicted bounding boxes\n",
    "    for (res_i, res_box) in enumerate(result_box):\n",
    "        c = 'k'\n",
    "        xs, ys = zip(*res_box)\n",
    "        xs += (xs[0],)\n",
    "        ys += (ys[0],)            \n",
    "        l = 'predicted' if res_i == 0 else f'_res_{res_i}'\n",
    "        plt.plot(xs,ys, 'w', label='_res_bg', linewidth=10)\n",
    "        plt.plot(xs,ys, 'k', label=l, linewidth=5)\n",
    "    \n",
    "    # Draw real bounding boxes\n",
    "    for (rea_i, rea_box) in enumerate(real_box):\n",
    "        xs, ys = zip(*rea_box)\n",
    "        xs += (xs[0],)\n",
    "        ys += (ys[0],)    \n",
    "        l = 'real bounds' if rea_i == 0 else f'_rea_{rea_i}'\n",
    "        plt.plot(xs,ys, 'w+', label='_real_bg', mew=8, ms=35)\n",
    "        plt.plot(xs,ys, 'g+', label=l, mew=5, ms=30)\n",
    "        \n",
    "    plt.legend(fontsize = 20)\n",
    "    plt.show()\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2144bf-7ea2-48ca-b775-937031d32647",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c490e-67bf-480f-8251-00136fffcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "\n",
    "try: real_values\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run prior cell\"))\n",
    "    \n",
    "# Assume all same shape\n",
    "rea_canvas = np.zeros(real_values[0][\"image\"].shape[:2], dtype=np.float32)\n",
    "res_canvas = np.zeros(real_values[0][\"image\"].shape[:2], dtype=np.float32)\n",
    "for (rea, res) in zip(real_values, result_values):\n",
    "    rea_canvas[:,:] = 0\n",
    "    res_canvas[:,:] = 0\n",
    "    # Render the real bounds\n",
    "    for box in rea[\"bounds\"]:\n",
    "        cv2.fillPoly(rea_canvas, pts =[np.array(box)], color =(1))\n",
    "    # Render the result bounds\n",
    "    for box in res[\"bounds\"]:\n",
    "        cv2.fillPoly(res_canvas, pts =[np.array(box)], color =(1))\n",
    "\n",
    "    # Calculate the union\n",
    "    union = np.logical_or(rea_canvas > 0, res_canvas > 0)\n",
    "    intersection = np.logical_and(rea_canvas > 0, res_canvas > 0)\n",
    "    iou = round(100 * (intersection.sum() / union.sum()))\n",
    "    ious.append(iou)\n",
    "    if len(ious) % 10 == 0:\n",
    "        print(round(100*len(ious)/len(real_values)),'%')\n",
    "\n",
    "setup_plt(True)\n",
    "bin_range = list(range(0,100,10))\n",
    "plt.gca().xaxis.grid(True, color='k')\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.hist(ious, bins = bin_range, density = True)\n",
    "plt.title(f'Histogram of IOU (intersection over Union)', fontsize = 50)\n",
    "plt.tick_params(axis='both', which='major', labelsize = 30)\n",
    "plt.xticks(bin_range, [f'{x//10}/10' for x in bin_range])\n",
    "\n",
    "plt.xticks(bin_range)\n",
    "plt.xlabel(\"IOU as ratio\", fontsize=40)\n",
    "plt.ylabel(\"Frequency of range\", fontsize=40)\n",
    "plt.show() # TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9de6e-af35-4179-b072-4f71bca6d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: ious\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run prior cell\"))\n",
    "    \n",
    "MEAN_IOU = np.mean(ious)\n",
    "TEXT_EQUALITY = [a[\"text\"] == b[\"text\"] for (a, b) in zip(real_values, result_values)]\n",
    "TEXT_ACCURACY = int(np.array(TEXT_EQUALITY, dtype=bool).sum())/len(TEXT_EQUALITY)\n",
    "MEAN_CORRECT_IOU = np.mean(np.array(ious)[TEXT_EQUALITY])\n",
    "\n",
    "print(f'{round(MEAN_IOU, 3)}% mean IOU')\n",
    "print(f'   {round(MEAN_CORRECT_IOU, 3)}% for true predictions')\n",
    "print(f'\\n{round(TEXT_ACCURACY*100, 3)}% text accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f969e8-e183-4e69-a2e9-57735f02a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample as samp\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e40f6a-a363-4491-89a8-05723940c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: TEXT_EQUALITY\n",
    "except NameError:\n",
    "    raise(Exception(\"Please run prior cell\"))\n",
    "\n",
    "N_GPT = 5\n",
    "DELAY_GPT = 2.0\n",
    "\n",
    "#api request instructions\n",
    "def chat_with_gpt(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine = 'text-davinci-003',\n",
    "        prompt = prompt,\n",
    "        max_tokens = 128,\n",
    "        temperature = 0.5,\n",
    "        n = 1,\n",
    "        stop = None\n",
    "    )\n",
    "\n",
    "    #index selection of the responses generated by ChatGPT; choosing the first one\n",
    "    if response.choices:\n",
    "        lines = response.choices[0].text.split('\\n')\n",
    "        lines[0] = lines[0].replace(', and',',')\n",
    "        lines[1] = lines[1].replace(', and',',')\n",
    "        lines[0] = lines[0].replace(',',' +')\n",
    "        lines[1] = lines[1].replace(',',' +')\n",
    "        return '\\n'.join(lines)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def to_prompt(spices):\n",
    "    s = ', '.join(spices)\n",
    "    return f'Please make a recipe from the following list of ingredients: {s}'\n",
    "\n",
    "found_spices = set([v[\"text\"] for (t,v) in zip(TEXT_EQUALITY, result_values) if t])\n",
    "spice_lists = [samp(list(found_spices),samp([2,3,4],1)[0]) for _ in range(N_GPT)]\n",
    "print(len(found_spices), 'spices available!\\n')\n",
    "\n",
    "for spices in spice_lists:\n",
    "    clear_output(wait=True)\n",
    "    print('INPUT SPICES:')\n",
    "    prompt = to_prompt(spices)\n",
    "    print('-', prompt[60:])\n",
    "    output = chat_with_gpt(prompt)\n",
    "    output = re.sub(r'Instructions.*', '', output, re.DOTALL)\n",
    "    output = re.sub(r'\\n\\d.*', '', output, re.DOTALL)\n",
    "    print('\\nOUTPUT RECIPE:')\n",
    "    print(re.sub(r'Instructions.*', '', output))\n",
    "    time.sleep(DELAY_GPT)\n",
    "    print('\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
